{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fbb50f6",
   "metadata": {},
   "source": [
    "# azlyrics.com - Web Scraping Project\n",
    "### M.H."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab41933",
   "metadata": {},
   "source": [
    "### <span style=\"color: red\">The Objective:   <br> Creating a dataset of songs (including lyrics) recorded by artists whose name starts with letter H. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ba23639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# needed libraries\n",
    "\n",
    "import requests                      #<-- for requesting web content\n",
    "from bs4 import BeautifulSoup as bs #<-- for parsing through requested content\n",
    "import pandas as pd                #<-- for manipulating data\n",
    "from time import time, sleep      #<-- for incorporating time lapse in automatic web scraping\n",
    "from datetime import datetime    #<-- for recording current time\n",
    "from random import randint      #<-- for random assignment of time lapses\n",
    "from warnings import warn      #<-- for generating warnings when connection with server during auto collection is lost\n",
    "import re                     #<-- for conducting Regular Expression operations on Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bc0ef73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the url of a page on azlyrics.com for artists whose names begin with H\n",
    "url = \"https://www.azlyrics.com/h.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ade32639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accessing webpage for letter H artists and checking the status of connection (200 would be OK)\n",
    "page = requests.get(url)\n",
    "page.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5950f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsing through the page\n",
    "soup=bs(page.content,\"lxml\")\n",
    "\n",
    "# may want to run this to view:\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe1986e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolating the content in the main container on the page for letter H\n",
    "main = soup.find_all(class_=\"col-sm-6 text-center artist-col\")\n",
    "\n",
    "# may want to run this to view:\n",
    "main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6adaf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main column is devided into 2 columns\n",
    "# isolating the left column of the list\n",
    "left = main[0]\n",
    "\n",
    "# this is the right column of the list \n",
    "right = main[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b24d4b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "669"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selecting only names (<a> links) in both, right and left columns\n",
    "right_a_tags = right.find_all(\"a\")\n",
    "left_a_tags = left.find_all(\"a\")\n",
    "# concatenating both, left and right lists of links and checking how many (number of artists under letter h)\n",
    "page_artists = left_a_tags + right_a_tags\n",
    "len(page_artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64d1fe87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['H1GHR MUSIC', 'Ha-Ash', 'Hackett, Emily', 'Hackett, Steve', 'Hackman, Marika', 'Hacktivist', 'Haddaway', 'Haddon, Deitrick', 'Hadestown Cast', 'Hadise']\n"
     ]
    }
   ],
   "source": [
    "# creating 2 lists, one for artists' names and one for their URLs' unique tale portions \n",
    "artists_names = []\n",
    "artists_links = []\n",
    "for i in page_artists:\n",
    "    artists_names.append(i.text)\n",
    "    artists_links.append(i.get(\"href\"))\n",
    "# printing first 10 elements of artists_names for review\n",
    "print(artists_names[0:10]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b99db3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['h/h1ghrmusic.html', 'h/haash.html', 'e/emilyhackett.html', 's/stevehackett.html', 'm/marikahackman.html', 'h/hacktivist.html', 'h/haddaway.html', 'd/deitrickhaddon.html', 'h/hadestowncast.html', 'h/hadise.html']\n"
     ]
    }
   ],
   "source": [
    "# printing first 10 elements of artists_links for review\n",
    "print(artists_links[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01a663b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "669"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# double-checking if the number of names is the same as the original number of artists\n",
    "len(artists_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "946b92c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "669"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# double-checking if the number of url-tails is the same as the original number of artists\n",
    "len(artists_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a020a52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.azlyrics.com/h/h1ghrmusic.html',\n",
       " 'https://www.azlyrics.com/h/haash.html',\n",
       " 'https://www.azlyrics.com/e/emilyhackett.html']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating new list for artists' URLs by concatenating the missing head portion to urls in the artists_links\n",
    "artists_urls = []\n",
    "for link in artists_links:\n",
    "    artists_urls.append(\"https://www.azlyrics.com/\" + link)\n",
    "artists_urls[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aed27f9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('H1GHR MUSIC', 'https://www.azlyrics.com/h/h1ghrmusic.html'),\n",
       " ('Ha-Ash', 'https://www.azlyrics.com/h/haash.html'),\n",
       " ('Hackett, Emily', 'https://www.azlyrics.com/e/emilyhackett.html')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the list of tuples containing both, artist's name and the URL to the artist's page on azlyrics.com\n",
    "name_url_list = list(zip(artists_names, artists_urls))\n",
    "# reviewing fist 3 rows\n",
    "name_url_list[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61636de",
   "metadata": {},
   "source": [
    "### <span style=\"color: red\">Scraping songs' titles with their respective URLs for all artists whose name starts with H </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "864f4783",
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_name = []   # <-- collecting each song's artist name\n",
    "song_title = []    # <-- collecting songs' titles\n",
    "song_url = []      # <-- collecting the url to each song's lyrics\n",
    "year = []          # <-- collecting each song's album year (if exists, if not it will have \"Missing\" instead)\n",
    "lapses = []     # <-- the list of actual time lapses in the scraping process between requests for each artist's page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e4e3f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "request_count = 0   # <-- reflect the number of artists whose page with songs was requested\n",
    "title = ''    # <-- to hold the title of song\n",
    "now = datetime.now()\n",
    "begin_time = now.strftime(\"%H:%M:%S\") # <-- time when scraping started\n",
    "\n",
    "# scraping titles of songs, their lyrics-URLs, and a year of recording for artists in the collected list (669)\n",
    "for artist in name_url_list[0:669]:  \n",
    "    name = artist[0]\n",
    "    artist_url = artist[1]\n",
    "    start_time = time()   # <-- time when the artist's page is requested\n",
    "    request_count += 1\n",
    "    artist_page = requests.get(artist_url)\n",
    "    if artist_page.status_code != 200:\n",
    "        warn('Request: {}; Status code: {}'.format(request_count, artist_page.status_code))\n",
    "    soup = bs(artist_page.content, 'lxml')\n",
    "    sleep(randint(6,15))    # <-- randomly generated time-lapse added between requests\n",
    "    \n",
    "    a = soup.find('div', {'id':{'listAlbum'}})\n",
    "    b = soup.find('div', {'class':{'col-xs-12 col-lg-8 text-center'}})\n",
    "    if (a is not None):\n",
    "        container = a\n",
    "    elif(b is not None):\n",
    "        container = b \n",
    "    else:  \n",
    "        container = None\n",
    "   \n",
    "    if (container != None):\n",
    "        divs = container.find_all('div') \n",
    "        album_year = 'Missing'\n",
    "        for div in divs: \n",
    "            if div.has_attr('class'):\n",
    "                if div.attrs['class'][0] == 'album':\n",
    "                    if div.text == 'other songs:':\n",
    "                        album_year = 'Missing'\n",
    "                    else:\n",
    "                        str = div.text[-5:-1]\n",
    "                        x = re.search('^19', str)    # <-- checking if the last text section of div starts with 19\n",
    "                        y = re.search('^20', str)    # <-- checking if the last text section of div starts with 20\n",
    "                        if (x == None and y == None):\n",
    "                            album_year = 'Missing'   # <-- if not, the year is not listed\n",
    "                        else:\n",
    "                            album_year = str\n",
    "                elif div.attrs['class'][0] == 'listalbum-item':\n",
    "                    lyrics_link = div.find('a')\n",
    "                    if(lyrics_link is None):\n",
    "                        title = div.text\n",
    "                        fixed_url = \"Missing\"\n",
    "                    else:\n",
    "                        title = div.a.text      \n",
    "                        song_link = div.a.get(\"href\")\n",
    "                        z = re.search('^http', song_link)   # <-- some href already contain full webpage link to lyrics\n",
    "                        if (z == None):\n",
    "                            fixed_url = \"https://www.azlyrics.com/\" + song_link.lstrip(\"../\")\n",
    "                        else:\n",
    "                            fixed_url = song_link        \n",
    "                    artist_name.append(name) \n",
    "                    song_title.append(title)\n",
    "                    year.append(album_year)\n",
    "                    song_url.append(fixed_url) \n",
    "                    \n",
    "    elapsed_time = time() - start_time \n",
    "    lapses.append(elapsed_time)   \n",
    "    now = datetime.now()\n",
    "    end_time = now.strftime(\"%H:%M:%S\")    # <-------------------- time when scraping ended\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f1e8287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time of scraping was 2 hours and 1 minutes\n",
      "Beginning time: 09:33:46\n",
      "End time: 11:35:26\n"
     ]
    }
   ],
   "source": [
    "# calculating the total time this part of scraping took:\n",
    "import math\n",
    "\n",
    "scrape_time = 0\n",
    "for i in lapses:\n",
    "    scrape_time += i\n",
    "scrape_time_hours = math.floor(scrape_time/3600)  # <-- number of hours (each hour has 3600 seconds)\n",
    "scrape_time_min = math.floor((scrape_time%3600)/60)  # <-- number of minutes (remainder of seconds divided by 60)\n",
    "print(f'Total time of scraping was {scrape_time_hours} hours and {scrape_time_min} minutes')\n",
    "print(f'Beginning time: {begin_time}')\n",
    "print(f'End time: {end_time}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9d89803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "669"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lapses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b06c83e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "669"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ffeb5157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "668"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(artist_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77946b4",
   "metadata": {},
   "source": [
    "### <span style=\"color: red;\"> Now, checking lenghts of all 4 lists filled during the web-scraping process.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "89babe22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42529"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(artist_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0a314c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42529"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(song_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "355017bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42529"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38573c35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42529"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(song_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "160ee6b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist_Name</th>\n",
       "      <th>Song_Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>Lyrics_URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>H1GHR MUSIC</td>\n",
       "      <td>H1GHR</td>\n",
       "      <td>2020</td>\n",
       "      <td>https://www.azlyrics.com/lyrics/h1ghrmusic/h1g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>H1GHR MUSIC</td>\n",
       "      <td>Melanin Handsome</td>\n",
       "      <td>2020</td>\n",
       "      <td>https://www.azlyrics.com/lyrics/h1ghrmusic/mel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>H1GHR MUSIC</td>\n",
       "      <td>How We Rock</td>\n",
       "      <td>2020</td>\n",
       "      <td>https://www.azlyrics.com/lyrics/h1ghrmusic/how...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Artist_Name        Song_Title  Year  \\\n",
       "0  H1GHR MUSIC             H1GHR  2020   \n",
       "1  H1GHR MUSIC  Melanin Handsome  2020   \n",
       "2  H1GHR MUSIC       How We Rock  2020   \n",
       "\n",
       "                                          Lyrics_URL  \n",
       "0  https://www.azlyrics.com/lyrics/h1ghrmusic/h1g...  \n",
       "1  https://www.azlyrics.com/lyrics/h1ghrmusic/mel...  \n",
       "2  https://www.azlyrics.com/lyrics/h1ghrmusic/how...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# joining all 4 lists into one dataframe\n",
    "all_data = pd.DataFrame(list(zip(artist_name,song_title,year,song_url)),\n",
    "               columns =['Artist_Name', 'Song_Title', 'Year', 'Lyrics_URL'])\n",
    "all_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "805366cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving current data (no lyrics column yet) into the csv file (as backup record of raw data that was collected)\n",
    "all_data.to_csv(r'all_data.csv', index=True)    # <-- insert preferable directory link where you want to save the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6adc06ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42529, 4)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# current size of dataframe\n",
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fe1f4fca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34838, 4)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing rows with \"Missing\" in the Year or Lyrics_URL column and any other rows with missing values\n",
    "all_data = all_data[(all_data.Year != 'Missing') & (all_data.Lyrics_URL != 'Missing')]\n",
    "\n",
    "# removing rows with no value in any of the columns\n",
    "all_data = all_data.dropna(how='any',axis=0)\n",
    "\n",
    "# size of data after the removal of rows \n",
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "55ed1b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34760, 4)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing dublicates \n",
    "all_data = all_data.drop_duplicates(keep=\"first\")\n",
    "all_data = all_data.reset_index(drop=True)\n",
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0edeb35f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist_Name</th>\n",
       "      <th>Song_Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>Lyrics_URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>34760</td>\n",
       "      <td>34760</td>\n",
       "      <td>34760</td>\n",
       "      <td>34760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>599</td>\n",
       "      <td>29530</td>\n",
       "      <td>71</td>\n",
       "      <td>33921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Haggard, Merle</td>\n",
       "      <td>Intro</td>\n",
       "      <td>2020</td>\n",
       "      <td>https://www.azlyrics.com/lyrics/ferlinhusky/go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>611</td>\n",
       "      <td>27</td>\n",
       "      <td>1854</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Artist_Name Song_Title   Year  \\\n",
       "count            34760      34760  34760   \n",
       "unique             599      29530     71   \n",
       "top     Haggard, Merle      Intro   2020   \n",
       "freq               611         27   1854   \n",
       "\n",
       "                                               Lyrics_URL  \n",
       "count                                               34760  \n",
       "unique                                              33921  \n",
       "top     https://www.azlyrics.com/lyrics/ferlinhusky/go...  \n",
       "freq                                                    6  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note:the multiple occurance (frequency) of the same Lyrics_URL link to the song reflects recordings\n",
    "# of the same song in different years or by different artist\n",
    "all_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "65fe8ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1952', '1953', '1954', '1955', '1956', '1957', '1958', '1959', '1960', '1961', '1962', '1963', '1964', '1965', '1966', '1967', '1968', '1969', '1970', '1971', '1972', '1973', '1974', '1975', '1976', '1977', '1978', '1979', '1980', '1981', '1982', '1983', '1984', '1985', '1986', '1987', '1988', '1989', '1990', '1991', '1992', '1993', '1994', '1995', '1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022']\n"
     ]
    }
   ],
   "source": [
    "# checking which years are represented \n",
    "print(sorted(all_data['Year'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1d538a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Artist_Name    object\n",
       "Song_Title     object\n",
       "Year            int32\n",
       "Lyrics_URL     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting \"Year\" column's data type to integer \n",
    "all_data['Year'] = all_data.Year.astype(int)\n",
    "\n",
    "all_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997faaff",
   "metadata": {},
   "source": [
    "### <span style=\"color: red\">Now we scrape the lyrics for every song listed in the current dataframe and add them to the new column \"Lyrics\". </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365c403b",
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_lyrics = []       # <-- list to hold collected lyrics \n",
    "urls = list(all_data['Lyrics_URL'])  # <-- list of URLs to lyrics that we want to collect \n",
    "div_error = 'ERROR'     # <-- if lyrics are not available, this String will be inserted as lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c315fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code below can be run in increments (e.g., for every 5K songs each time) or at once for all\n",
    "# items in the all_data table (i.e.,34,760 songs);\n",
    "# It is useful to know that many website servers have bot detection systems, mainly to protect servers from\n",
    "# being overwhelmed with requests, thus your scraping session, if detected, may be terminated. In such case,\n",
    "# you can continue scraping after checking where the download was left off (in this case, what was the index of \n",
    "# the last song lyrics appended to the songs_lyrics list which corelates with the index of the last song url \n",
    "# being processes).\n",
    "\n",
    "request_count = 0\n",
    "lapses = []     # <-- the list of actual time lapses in the scraping process between requests\n",
    "now = datetime.now()\n",
    "begin_time = now.strftime(\"%H:%M:%S\") # <-- time when scraping started\n",
    "\n",
    "for song_url in urls[0:34760]:   # <---- ***here is where you put the range of indexes you want to scrape lyrics for***\n",
    "    start_time = time()   # <-- time when the artist's page is requested\n",
    "    request_count += 1\n",
    "    page = requests.get(song_url)\n",
    "    if page.status_code != 200:\n",
    "        warn('Request: {}; Status code: {}'.format(request, page.status_code))\n",
    "    soup = bs(page.content, 'lxml')\n",
    "    sleep(randint(8,17))    # <-- randomly generated time-lapses added between requests\n",
    "    try:\n",
    "        x = soup.find('div', {'class':{\"col-xs-12 col-lg-8 text-center\"}})\n",
    "        divs = x.find_all('div') \n",
    "        y = divs[5].text\n",
    "        y = re.sub(\",\", \";\", y)     # <-- replacing all commas with semicolons\n",
    "        songs_lyrics.append(y)  \n",
    "    \n",
    "    except:\n",
    "        songs_lyrics.append(div_error)\n",
    "        \n",
    "    elapsed_time = time() - start_time \n",
    "    lapses.append(elapsed_time)   \n",
    "    now = datetime.now()\n",
    "    end_time = now.strftime(\"%H:%M:%S\")    # <-------------------- time when scraping ended\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124c6710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the total time this part of scraping took:\n",
    "scrape_time = 0\n",
    "for i in lapses:\n",
    "    scrape_time += i\n",
    "scrape_time_hours = math.floor(scrape_time/3600)  # <-- number of hours (each hour has 3600 seconds)\n",
    "scrape_time_min = math.floor((scrape_time%3600)/60)  # <-- number of minutes (remainder of seconds divided by 60)\n",
    "print(f'Total time of scraping was {scrape_time_hours} hours and {scrape_time_min} minutes')\n",
    "print(f'Beginning time: {begin_time}')\n",
    "print(f'End time: {end_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d371b004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shows how many song lyrics were appended\n",
    "len(songs_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5685b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shows how many laps times were recorded\n",
    "len(lapses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605422e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of processed page requests\n",
    "request_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af4eb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa31e1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding collected lyrics to the dataframe\n",
    "collected_data = pd.DataFrame(all_data) \n",
    "collected_data['Lyrics'] = songs_lyrics \n",
    "collected_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9ed115",
   "metadata": {},
   "outputs": [],
   "source": [
    "collected_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3dea06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving all collected raw data into a .csv file:\n",
    "collected_data.to_csv(r'collected_data.csv', index=False)  #<--insert preferable directory link where you want to save the file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d34450",
   "metadata": {},
   "source": [
    "### <span style=\"color: red;\"> Post-Web-Scraping Tasks and Saving of the Final Dataset Ready for Future Analysis.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4c77e6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data from saved .csv file \n",
    "data = pd.read_csv(r'collected_data.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "84cab7a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Artist_Name', 'Song_Title', 'Year', 'Lyrics_URL', 'Lyrics'], dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "06b3652a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Artist_Name    0\n",
       "Song_Title     0\n",
       "Year           0\n",
       "Lyrics_URL     0\n",
       "Lyrics         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking if there are any rows with missing values:\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "efeae60a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist_Name</th>\n",
       "      <th>Song_Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>Lyrics_URL</th>\n",
       "      <th>Lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2364</th>\n",
       "      <td>Haley, Gavin</td>\n",
       "      <td>Intro</td>\n",
       "      <td>2022</td>\n",
       "      <td>https://www.azlyrics.com/lyrics/gavinhaley/int...</td>\n",
       "      <td>\\n\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2365</th>\n",
       "      <td>Haley, Gavin</td>\n",
       "      <td>Blue Hour</td>\n",
       "      <td>2022</td>\n",
       "      <td>https://www.azlyrics.com/lyrics/gavinhaley/blu...</td>\n",
       "      <td>\\n\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2366</th>\n",
       "      <td>Haley, Gavin</td>\n",
       "      <td>Lottery</td>\n",
       "      <td>2022</td>\n",
       "      <td>https://www.azlyrics.com/lyrics/gavinhaley/lot...</td>\n",
       "      <td>\\n\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2368</th>\n",
       "      <td>Haley, Gavin</td>\n",
       "      <td>Heroes</td>\n",
       "      <td>2022</td>\n",
       "      <td>https://www.azlyrics.com/lyrics/gavinhaley/her...</td>\n",
       "      <td>\\n\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2369</th>\n",
       "      <td>Haley, Gavin</td>\n",
       "      <td>Drifting Away</td>\n",
       "      <td>2022</td>\n",
       "      <td>https://www.azlyrics.com/lyrics/gavinhaley/dri...</td>\n",
       "      <td>\\n\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32966</th>\n",
       "      <td>HUNNY</td>\n",
       "      <td>New Recording 122 August 19, 2020</td>\n",
       "      <td>2022</td>\n",
       "      <td>https://www.azlyrics.com/lyrics/hunny/newrecor...</td>\n",
       "      <td>\\n\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34101</th>\n",
       "      <td>Hutchinson, Eric</td>\n",
       "      <td>Right Side Of History</td>\n",
       "      <td>2022</td>\n",
       "      <td>https://www.azlyrics.com/lyrics/erichutchinson...</td>\n",
       "      <td>\\n\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34102</th>\n",
       "      <td>Hutchinson, Eric</td>\n",
       "      <td>The Littlest Candle</td>\n",
       "      <td>2022</td>\n",
       "      <td>https://www.azlyrics.com/lyrics/erichutchinson...</td>\n",
       "      <td>\\n\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34103</th>\n",
       "      <td>Hutchinson, Eric</td>\n",
       "      <td>Pick Up The Pace</td>\n",
       "      <td>2022</td>\n",
       "      <td>https://www.azlyrics.com/lyrics/erichutchinson...</td>\n",
       "      <td>\\n\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34104</th>\n",
       "      <td>Hutchinson, Eric</td>\n",
       "      <td>Sing Along With Me</td>\n",
       "      <td>2022</td>\n",
       "      <td>https://www.azlyrics.com/lyrics/erichutchinson...</td>\n",
       "      <td>\\n\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Artist_Name                         Song_Title  Year  \\\n",
       "2364       Haley, Gavin                              Intro  2022   \n",
       "2365       Haley, Gavin                          Blue Hour  2022   \n",
       "2366       Haley, Gavin                            Lottery  2022   \n",
       "2368       Haley, Gavin                             Heroes  2022   \n",
       "2369       Haley, Gavin                      Drifting Away  2022   \n",
       "...                 ...                                ...   ...   \n",
       "32966             HUNNY  New Recording 122 August 19, 2020  2022   \n",
       "34101  Hutchinson, Eric              Right Side Of History  2022   \n",
       "34102  Hutchinson, Eric                The Littlest Candle  2022   \n",
       "34103  Hutchinson, Eric                   Pick Up The Pace  2022   \n",
       "34104  Hutchinson, Eric                 Sing Along With Me  2022   \n",
       "\n",
       "                                              Lyrics_URL Lyrics  \n",
       "2364   https://www.azlyrics.com/lyrics/gavinhaley/int...   \\n\\n  \n",
       "2365   https://www.azlyrics.com/lyrics/gavinhaley/blu...   \\n\\n  \n",
       "2366   https://www.azlyrics.com/lyrics/gavinhaley/lot...   \\n\\n  \n",
       "2368   https://www.azlyrics.com/lyrics/gavinhaley/her...   \\n\\n  \n",
       "2369   https://www.azlyrics.com/lyrics/gavinhaley/dri...   \\n\\n  \n",
       "...                                                  ...    ...  \n",
       "32966  https://www.azlyrics.com/lyrics/hunny/newrecor...   \\n\\n  \n",
       "34101  https://www.azlyrics.com/lyrics/erichutchinson...   \\n\\n  \n",
       "34102  https://www.azlyrics.com/lyrics/erichutchinson...   \\n\\n  \n",
       "34103  https://www.azlyrics.com/lyrics/erichutchinson...   \\n\\n  \n",
       "34104  https://www.azlyrics.com/lyrics/erichutchinson...   \\n\\n  \n",
       "\n",
       "[116 rows x 5 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chacking if there are any missing or incorrect values in the lyrics column\n",
    "data[data['Lyrics'].isin([\"\\n\\n\", \"ERROR\", ''])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9c1dd38c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Artist_Name    0\n",
       "Song_Title     0\n",
       "Year           0\n",
       "Lyrics_URL     0\n",
       "Lyrics         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking if there are any missing values:\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4f723933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34688, 5)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# current size of data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a9978832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34572, 5)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing rows with error in the Lyrics column\n",
    "data.drop(data[data['Lyrics'].isin([\"\\n\\n\", \"ERROR\", ''])].index, inplace = True)\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# new size of dataset\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b946214e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist_Name</th>\n",
       "      <th>Song_Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>Lyrics_URL</th>\n",
       "      <th>Lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34571</th>\n",
       "      <td>HyunA</td>\n",
       "      <td>FLOWER SHOWER</td>\n",
       "      <td>2021</td>\n",
       "      <td>https://www.azlyrics.com/lyrics/hyuna/flowersh...</td>\n",
       "      <td>\\n\\n[Romanized:]\\n\\nI just wanna be your flowe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Artist_Name     Song_Title  Year  \\\n",
       "34571       HyunA  FLOWER SHOWER  2021   \n",
       "\n",
       "                                              Lyrics_URL  \\\n",
       "34571  https://www.azlyrics.com/lyrics/hyuna/flowersh...   \n",
       "\n",
       "                                                  Lyrics  \n",
       "34571  \\n\\n[Romanized:]\\n\\nI just wanna be your flowe...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# viewing the very last row in the dataframe\n",
    "data.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a0337437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artist_Name: HyunA\n",
      "Song_Title: FLOWER SHOWER\n",
      "Year: 2021\n",
      "Lyrics_URL: https://www.azlyrics.com/lyrics/hyuna/flowershower.html\n",
      "-----------------------------------------------------\n",
      "Lyrics: \n",
      "\n",
      "[Romanized:]\n",
      "\n",
      "I just wanna be your flower saeppalgaeyo nan\n",
      "Hyanggiroun hyanggiro beolttedeuri kkoyeo\n",
      "Hok shideureodo Don't you worry dashi pijana\n",
      "Pieonaneun nae Color shiseondeuri moyeo\n",
      "\n",
      "Ppanhi nareul barabwa geureon gwanshimi nan\n",
      "Shilchi ana shilchi ana Eh eh\n",
      "Dashi pieonaneun kkot Just gotta let it go OK\n",
      "Can you hear me now\n",
      "\n",
      "Ije kkotgillo na georeogal kkeoya\n",
      "Geurae kkotteullo shaweohal kkeoya\n",
      "\n",
      "Take a flower shower (woo hoo woo hoo)\n",
      "Ssodajineun Flower\n",
      "Sing it; sing it babe\n",
      "Wing it; wing it babe\n",
      "Bring it; bring it babe\n",
      "Kkotyanggiga nane Eh eh\n",
      "Like doomda doomda\n",
      "Like doomda doomda\n",
      "\n",
      "I'mma be forever young saeparaeyo nan\n",
      "Bomi omyeon Get set go saero pieonayo\n",
      "Seodureuji ma gyejeolcheoreom doraojana\n",
      "Meoributeo balkkeutkkaji hyeonaneun ppalgaeyo\n",
      "\n",
      "Nal jom naebeoryeo dweobwa maeume eomneun mal\n",
      "Give me your like; give me your like eh eh\n",
      "Jangmikkochijana Feel-i kkochijana OK\n",
      "Let's sing this song\n",
      "\n",
      "Ije kkotgillo na georeogal kkeoya\n",
      "Geurae kkotteullo shaweohal kkeoya\n",
      "\n",
      "Take a flower shower (woo hoo woo hoo)\n",
      "Ssodajineun Flower\n",
      "Sing it; sing it babe\n",
      "Wing it; wing it babe\n",
      "Bring it; bring it babe\n",
      "Kkotyanggiga nane Eh eh\n",
      "\n",
      "Yeongweonhal kkeora mideo eoneu nare kkotcheoreom\n",
      "Urineun wae moreuneun geolkka\n",
      "Anim moreun chehaneun geolkka Eh eh\n",
      "Jil ttae jideorado hwaljjak pillae\n",
      "Haneul haneul haneure nalline\n",
      "Never give up and I say never say never ooh\n",
      "\n",
      "Take a flower shower\n",
      "Ssodajineun Flower\n",
      "Sing it; sing it babe\n",
      "Wing it; wing it babe\n",
      "Bring it; bring it babe\n",
      "Kkotyanggiga nane Eh eh\n",
      "\n",
      "[Korean:]\n",
      "\n",
      "I just wanna be your flower 새빨개요 난\n",
      "향기로운 향기로 벌떼들이 꼬여\n",
      "혹 시들어도 Don't you worry 다시 피잖아\n",
      "피어나는 내 Color 시선들이 모여\n",
      "\n",
      "빤히 나를 바라봐 그런 관심이 난\n",
      "싫지 않아 싫지 않아 Eh eh\n",
      "다시 피어나는 꽃 Just gotta let it go OK\n",
      "Can you hear me now\n",
      "\n",
      "이제 꽃길로 나 걸어갈 거야\n",
      "그래 꽃들로 샤워할 거야\n",
      "\n",
      "Take a flower shower (woo hoo woo hoo)\n",
      "쏟아지는 Flower\n",
      "Sing it; sing it babe\n",
      "Wing it; wing it babe\n",
      "Bring it; bring it babe\n",
      "꽃향기가 나네 Eh eh\n",
      "Like doomda doomda\n",
      "Like doomda doomda\n",
      "\n",
      "I'mma be forever young 새파래요 난\n",
      "봄이 오면 Get set go 새로 피어나요\n",
      "서두르지 마 계절처럼 돌아오잖아\n",
      "머리부터 발끝까지 현아는 빨개요\n",
      "\n",
      "날 좀 내버려 둬봐 마음에 없는 말\n",
      "Give me your like; give me your like eh eh\n",
      "장미꽃이잖아 Feel이 꽂히잖아 OK\n",
      "Let's sing this song\n",
      "\n",
      "이제 꽃길로 나 걸어갈 거야\n",
      "그래 꽃들로 샤워할 거야\n",
      "\n",
      "Take a flower shower (woo hoo woo hoo)\n",
      "쏟아지는 Flower\n",
      "Sing it; sing it babe\n",
      "Wing it; wing it babe\n",
      "Bring it; bring it babe\n",
      "꽃향기가 나네 Eh eh\n",
      "\n",
      "영원할 거라 믿어 어느 날의 꽃처럼\n",
      "우리는 왜 모르는 걸까\n",
      "아님 모른 체하는 걸까 Eh eh\n",
      "질 때 지더라도 활짝 필래\n",
      "하늘 하늘 하늘에 날리네\n",
      "Never give up and I say never say never ooh\n",
      "\n",
      "Take a flower shower\n",
      "쏟아지는 Flower\n",
      "Sing it; sing it babe\n",
      "Wing it; wing it babe\n",
      "Bring it; bring it babe\n",
      "꽃향기가 나네 Eh eh\n",
      "\n",
      "[English translation:]\n",
      "\n",
      "I just wanna be your flower; freshly red\n",
      "With my flowery scent; I lure in all the bees\n",
      "Even as flowers wither; don't you worry; they will bloom again\n",
      "As I bloom in vivid colors; everyone stares at me\n",
      "\n",
      "They're all looking at me now; all of this attention\n",
      "I don't hate it\n",
      "Flowers bloom again; just gotta let it go; OK\n",
      "Can you hear me now\n",
      "\n",
      "I'm paving my own floral path\n",
      "I'm gonna shower myself with flowers\n",
      "\n",
      "Take a flower shower\n",
      "Shower me with flowers\n",
      "Sing it; sing it babe\n",
      "Wing it; wing it babe\n",
      "Bring it; bring it babe\n",
      "Doused in flowery scent\n",
      "Like doomda doomda\n",
      "Like doomda doomda\n",
      "\n",
      "I'mma be forever young; fresh and green\n",
      "When spring comes; get; set; go; I bloom anew\n",
      "Don't be hasty; just like seasons; everything will return\n",
      "From head to toe; HyunA is red\n",
      "\n",
      "Just let me be; you don't mean what you say\n",
      "Give me your like; give me your like eh eh\n",
      "It's like a rose; it's the same feeling; OK\n",
      "Let's sing this song\n",
      "\n",
      "I'm paving my own floral path\n",
      "I'm gonna shower myself with flowers\n",
      "\n",
      "Take a flower shower\n",
      "Shower me with flowers\n",
      "Sing it; sing it babe\n",
      "Wing it; wing it babe\n",
      "Bring it; bring it babe\n",
      "Doused in flowery scent\n",
      "\n",
      "I believe in forever; like a flower\n",
      "Why don't we all believe in forever?\n",
      "Or are we just in denial?\n",
      "Even if I wither; I want to bloom brightly\n",
      "Paint the sky with my vivid colors\n",
      "Never give up and I say never say never\n",
      "\n",
      "Take a flower shower\n",
      "Shower me with flowers\n",
      "Sing it; sing it babe\n",
      "Wing it; wing it babe\n",
      "Bring it; bring it babe\n",
      "Doused in flowery scent\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# viewing the sample data for one song in the created dataset; \n",
    "# this is the printout of data contained in the last row in the final dataset:\n",
    "\n",
    "print(f'Artist_Name: {data[\"Artist_Name\"][34571]}')\n",
    "print(f'Song_Title: {data[\"Song_Title\"][34571]}')\n",
    "print(f'Year: {data[\"Year\"][34571]}')\n",
    "print(f'Lyrics_URL: {data[\"Lyrics_URL\"][34571]}')\n",
    "print('-----------------------------------------------------')\n",
    "\n",
    "# the lyrics are listed in 3 linquistic forms: Romanized, Korean(original), and English translation.\n",
    "print(f'Lyrics: {data[\"Lyrics\"][34571]}')  # <-- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c9a0c791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1952 2022\n"
     ]
    }
   ],
   "source": [
    "# beginning and ending years of song recording contained in the created dataset:\n",
    "print(data['Year'].min(), data['Year'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fe2fafc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving final dataset of 34,572 songs recorded between years 1952-2022 by artists whose name starts with letter H\n",
    "data.to_csv(r'h_artists_songs.csv', index=False)  #<-- you can specify here the intended directory link to save this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "849a7e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34572, 5)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d583e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
